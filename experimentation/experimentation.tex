\chapter{Experimentación: modelos, \\entrenamiento y generación}

En este capítulo usaremos todos los conceptos vistos en los capítulos anteriores para justificar las elecciones de los diferentes modelos, hablaremos de las características principales de los mismos y finalmente entraremos en la fase del entrenamiento y los resultados de dichos modelos.



\input{preprocess/preprocess.tex}



\section{Resultados}

Habiendo preprocesado los datos, entrenado el modelo, guardado su estado y decidido el método de decodificación, estamos listos para poder generar comentarios. Se presentan aquí dos ejemplos generados al azar:

\begin{thm}
	\sffamily{
		Paediatric invasive immunosuppression (IPIS) in the treatment of recurrent kidney disease. Epidemiologic evidence suggests a association between immunosuppression and recurrence of recurrent kidney disease. Acute renal injury is a major risk factor for recurrent kidney disease. As the patient develops a family history of recurrence, his status will likely be monitored to determine whether he may benefit from continued immunosuppression.
	}
\end{thm}
\begin{thm}
	\sffamily{
		Predominant asymptomatic single cell carcinoma, melanoma, and cerebrovascular myopathy. The diagnosis of melanoma, cerebrovascular myopathy, and primary carcinoma requires extensive examination. Among these cancers, recurrent myopathy is a common occurrence. From 1980 to 1989, the incidence of melanoma, cerebrovascular myopathy, and secondary carcinoma increased from 8.5\% to 12.6\%.
	}
\end{thm}

Esto es solo una pequeña muestra. En la  Sección \ref{sec:comments} del Apéndice se exponen alguno más, por si su inspección resultase de interés. 

Se puede apreciar que, a veces, los comentarios son muy cortos, como el comentario \ref{com:short}. En contadas ocasiones el generador ha devuelto una línea vacía. 

En ocasiones, los comentarios pueden no ser rigurosos médicamente hablando, pero esto, de cara al análisis de las herramientas disponibles para el procesamiento de los comentarios, no es estrictamente necesario. Necesitamos que los comentarios incluyan conceptos que sean importantes y destacables, como tipos de enfermedades, medicaciones, etc. De esta forma, podremos analizar cómo las herramientas detectan diferentes tipos de información y cómo de fiables son. 

Es por ello que poseer un generador de comentarios nos resulta conveniente, ya que se pueden considerar muchos más casos, prácticamente de forma ilimitada.

\subsection{Métricas y calidad de los comentarios}

Uno de los grandes retos de la creación de modelos de lenguaje, a parte de en sí ser el desarrollo de los mismos extremadamente complejo, es la creación de métricas de calidad de los resultados obtenidos.

Con modelos clásicos que trabajan con números, o incluso imágenes, existe una serie de herramientas que permiten ofrecer, de forma objetiva, rigurosa y consistente, un valor cuantitativo que mide la calidad de la salida de dicho modelo.

En los modelos de lenguaje, y más aún, en los modelos generativos, obtener un valor cuantitativo que evalúe la calidad de los comentarios generados es, más que complicado, subjetivo.

La pregunta que nos hacemos realmente es: ?`cómo de buenos son los comentarios generados? ?`Son comentarios coherentes? ?`Son comentarios rigurosos? ?`Cómo podemos evaluar de forma automática un conjunto de comentarios suficientemente representativo?

Para solucionar estos problemas, se han inventado algunas técnicas, anuque las más relevantes son la métrica BLEU \cite{BLEU} y la métrica Rouge \cite{lin2004rouge}.

\subsubsection{BLEU}

\begin{equation}
	BLEU = min\left( 1, exp\left( 1 - \frac{ref_{length}}{output_{length}} \right) \right) \left( \prod^{4}_{i=1} precision_i \right)^{\frac{1}{4}}
\end{equation}

La métrica \textbf{B}i\textbf{L}ingual \textbf{E}valuation \textbf{U}nderstudy (BLEU) se ideó originalmente con objeto de evaluar traducciones automáticas. Dado un texto en un idioma y la traducción automática a otro, poder ofrecer un valor objetivo de cómo de bien se corresponden dichas oraciones. Esta tarea, como decíamos anteriormente, se compone de un importante carácter subjetivo, y es la razón por la que existen intérpretes y traductores que se encargan de este trabajo. La traducción de texto no es un mapeo directo de un conjunto de palabras de un idioma al de otro, ya que han de considerarse expresiones y valores culturales.

Dicho eso, disponer de, al menos, una medida que pueda servir de forma orientativa para evaluar la calidad de un traductor automático es, cuanto menos, conveniente.

El algoritmo en cuestión toma un conjunto de oraciones de referencia y otro conjunto de oraciones generadas que deseemos evaluar, y calcula un \textit{score} en función de cómo de probable es que una de las frases generadas pertenezca al conjunto de oraciones de referencia. Esta métrica también se utiliza extensamente en evaluación de modelos generativos de lenguaje, como el nuestro, ya que la naturaleza de la evaluación se corresponde directamente con la nuestro caso de uso.


Para evaluar el modelo, tomamos 100 oraciones aleatorias de nuestro conjunto de datos, y generamos 100 oraciones con nuestro modelo. El valor obtenido es de 0.0036. 

Por referencia, la misma métrica nos ofrece un valor entre 0 y 1, donde un valor de 0 indica un nulo solapamiento del texto generado con el valor de referencia, y un valor cercano a 1 indica una buena traducción del texto dadas las referencias obtenidas.

Hay que tener en cuenta que es una medida de \textbf{solapamiento} especialmente diseñada para la evaluación de la traducción automática, por lo que nuestro valor cercano a 0 no necesariamente indica una mala calidad de la generación de los comentarios.

\subsubsection{Rouge}
La métrica Recall-Oriented Understudy for Gisting Evaluation (Rouge) funciona de una manera muy similar, calculando el solapamiento de las palabras en los textos a comparar y haciendo especial énfasis en las diferencias entre el número de tokens, ya que es una métrica especialmente diseñada para la evaluación de resúmenes. En esta métrica se obtuvo un valor de 0.0669, indicando un supuestamente mal resumen del texto. 

\vspace{15mm}
Como vemos, no son medidas muy útiles para nuestro propósito, pero lo cierto es que no existen muchas otras alternativas para la evaluación automática del lenguaje generativo libre, ya que es una tarea tan intrínsecamente subjetiva, como mencionábamos antes. Existe una opción en \cite{yuan2021bartscore}, pero el código no ha sido publicado a día de hoy ya que continúa en desarrollo. 

Las medidas utilizadas anteriormente puede que no nos ofrezcan un valor objetivo de la calidad de los comentarios, pero sí nos ofrecen información acerca de su solapamiento.

\subsubsection{Similitud}
Esto nos lleva a otra métrica a utilizar: la distancia en los comentarios. Un factor que sí podemos determinar de forma sencilla es si los comentarios son muy similares entre sí. Idealmente, se desearía que el generador pudiera proporcionar comentarios que no estuvieran relacionados entre sí, ya que no se exploraría lo suficiente en el espacio de todas las posibles combinaciones de entidades que pudiésemos encontrar. En esencia, deseamos simular casos específicos y poco relacionados entre sí.

Para ello, podemos utilizar la medida de la distancia del coseno del valor TF-IDF mencionado en la  Sección \ref{sec:tfidf}. Calculando el valor TF-IDF de todos los comentarios generados y multiplicándolo por su traspuesta, generamos una matriz que nos define cómo de \textit{cerca} se encuentra cada comentario de todos los demás en el espacio latente. Podemos apreciar dicha matriz en la Figura \ref{fig:conf-tfidf}.

Se aprecia que la diagonal principal tiene un valor de 1, ya al comparar un comentario consigo mismo, estamos lo más cerca que se puede estar, o lo que es lo mismo, la distancia es 0.

Por lo general, todos los comentarios ofrecen valores de similitud muy bajos, que se intuye por la gran predominancia del color morado en la imagen, que corresponde con valores cercanos a 0.

\begin{figure}[h]
	\centering
	\includegraphics[width=.6\textwidth]{media/conf_matrix_tfidf.pdf}
	\caption{Matriz de comparativa de distancia de los 100 comentarios generados en todas las posibles combinaciones.}
	\label{fig:conf-tfidf}
\end{figure}



